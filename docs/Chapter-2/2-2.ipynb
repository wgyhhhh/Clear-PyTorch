{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68b22792",
   "metadata": {},
   "source": [
    "## 2.2.1 张量的创建形式\n",
    "\n",
    "PyTorch中创建张量主要有以下四种形式，我们将分别阐述。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a559c05",
   "metadata": {},
   "source": [
    "### 1. 通过内置函数`torch.tensor`创建张量\n",
    "\n",
    "第一种是利用`torch.tensor`函数来进行创建，如果事先有数据(例如NumPy数组和列表)，即可通过该方法进行转换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebce18cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.tensor([1,2,3,4]) # 转换列表为创建一维PyTorch张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f539f564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3,4]).dtype  # 查看张量的数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c25c1269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3,4], dtype=torch.float32)  # 指定数据类型为32位浮点数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1cacc4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3,4], dtype=torch.float32).dtype  # 查看张量的数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cc579b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(range(10)) # 创建包含0到9的整数张量  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45fdd490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3,4]).dtype  # 查看NumPy数组的数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6615c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4], dtype=torch.int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(np.array([1,2,3,4])) # 将NumPy数组转换为PyTorch张量 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d84ee319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(np.array([1,2,3,4])).dtype  # 查看转换后张量的数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e4d3cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1.0,2.0,3.0,4.0]).dtype  # 创建浮点型张量,默认数据类型为float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ae1f743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(np.array([1.0,2.0,3.0,4.0])).dtype  # NumPy默认浮点型为float64,转换后张量数据类型为float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5b0684a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1,2,3],[4,5,6]]) # 创建二维张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4c673d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1,  0,  0],\n",
       "        [-1,  0, -1],\n",
       "        [ 0, -1,  0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3,3).to(torch.int) # 创建3x3随机张量并转换为整数类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "907d11a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 8., 9.],\n",
       "        [7., 8., 5.],\n",
       "        [1., 4., 3.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0,10,(3,3)).to(torch.float) # 创建3x3整数随机张量并转换为浮点类型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221819d3",
   "metadata": {},
   "source": [
    "### 2. 通过PyTorch内置的函数创建张量\n",
    "\n",
    "第二种方法是使用PyTorch内置的函数创建张亮，通过指定张量的形状，返回给定形状的张量，如下所示：\n",
    "- `rand`用于生成服从[0,1)均匀分布的任意形状的张量\n",
    "- `randn`用于生成服从标准正态分布的任意形状的张量\n",
    "- `zeros`用于生成全部元素为0的张量\n",
    "- `ones`用于生成全部元素为1的张量\n",
    "- `eye`用于生成单位矩阵\n",
    "- `randint`用于生成一定形状的均匀分布的整数张量，整数上下限由自己确定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "167abfbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4374, 0.8520, 0.9069],\n",
       "        [0.8434, 0.4102, 0.9720],\n",
       "        [0.9221, 0.6522, 0.6439]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(3,3) # 创建3x3均匀分布随机张量，矩阵元素在[0,1)区间内"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0968be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0627, -0.4624,  2.1898, -1.1184],\n",
       "         [ 0.5683, -1.4234, -1.5605, -1.4103],\n",
       "         [-1.6682, -0.0248, -0.1780, -0.9024]],\n",
       "\n",
       "        [[ 2.1507,  1.9456,  1.7956, -0.0926],\n",
       "         [ 0.4394,  0.3144, -0.7923, -0.5728],\n",
       "         [ 0.7590, -0.3530,  1.5940,  0.9646]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2,3,4) # 创建2x3x4正态分布随机张量，张量元素服从均值为0，标准差为1的正态分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "164163e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2,2,3) # 创建2x2x3全零张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c055d53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2,2,2) # 创建2x2x2全一张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bb258eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(3) # 创建3x3单位矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0665dcc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9, 6, 8],\n",
       "        [5, 0, 6],\n",
       "        [4, 0, 2]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0,10,(3,3)) # 创建3x3随机整数张量,取值范围为0到9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334850cd",
   "metadata": {},
   "source": [
    "### 3. 通过已知张量创建形状相同的张量\n",
    "已知某一张量的形状，创建和已知向量相同形状的张量，虽然形状相同，但是元素不一定相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70097b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8699,  1.3527,  0.0665],\n",
       "        [-1.1648,  2.5015, -1.5826],\n",
       "        [ 0.6220,  0.7404,  0.9329]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(3,3)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f789c709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(t)  # 创建与张量t形状相同的全零张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e11353c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones_like(t)   # 创建与张量t形状相同的全一张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40031792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1332, 0.9111, 0.8449],\n",
       "        [0.3852, 0.4369, 0.8159],\n",
       "        [0.4101, 0.7016, 0.5624]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand_like(t)    # 创建与张量t形状相同的均匀分布随机张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd5cdcfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6159,  0.7497, -0.0205],\n",
       "        [-1.1452, -1.1132, -1.7022],\n",
       "        [ 0.5601, -0.0334,  1.0667]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn_like(t)  # 创建与张量t形状相同的正态分布随机张量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbe6bb7",
   "metadata": {},
   "source": [
    "### 4.通过已知张量构建形状不同但数据类型相同的张量\n",
    "该方法一般很少使用，具体来说，利用`new_tensor`创建的张量并不是`torch.int64`，而是和前面创建的张量的类型一样，即`torch.float32`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2610781a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.new_tensor([1,2,3]).dtype # 创建与张量t数据类型相同的新张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd8d1b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.new_zeros((2,2))  # 创建与张量t数据类型相同的2x2全零张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ddd4e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.new_ones((2,3))  # 创建与张量t数据类型相同的2x3全一张量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29076f4b",
   "metadata": {},
   "source": [
    "## 2.2.2 张量的存储设备\n",
    "一般来说，PyTorch张量主要在CPU和GPU两种设备上存储。在没有指定设备的情况下，其会默认存储到CPU上。如果想要转移张量到GPU上，需要在创建张量的函数的参数中指定`device`参数，如`device=\"cpu\"`，或`device=\"cuda:0\",...`来指定张量存储的位置。\n",
    "\n",
    "- 需要注意的是，GPU设备在PyTorch上以 cuda:0, cuda: 1,...指定，其中数字代表GPU设备的编号，如果一台设备有N个GPU，则GPU设备的编号分别为0,1,...,N-1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62bab4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9455,  0.4521,  1.5056],\n",
       "        [-1.9664,  0.6727, -0.3652],\n",
       "        [ 2.0790, -1.0259,  0.6850]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3, 3, device=\"cpu\") # 创建存储在CPU上的3x3正态分布随机张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "947e9a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3152, -0.4324,  0.2717],\n",
       "        [ 1.6675,  1.5972, -0.1475],\n",
       "        [ 1.6177, -0.4779,  0.7160]], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3, 3, device=\"cuda:0\") # 创建存储在GPU 0上的3x3正态分布随机张量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f23693",
   "metadata": {},
   "source": [
    "## 2.2.3 张量的维度变换\n",
    "\n",
    "深度学习中经常需要一些方法来获取张量的维度数目并进行一定的变换，下面介绍一些方法。\n",
    "- `ndimension`，可以获取张量维度的数目\n",
    "- `size`，可以得到张量的形状，指定某个具体维度还可以获得该维度的大小(-1,-2可以表示倒数第一个和倒数第二个维度)\n",
    "- `shape`，可以得到张量的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1303ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(2,3,4) # 创建2x3x4随机张量\n",
    "t.ndimension()  # 获取张量t的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6ee4b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.nelement()  # 获取张量t的元素总数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3db10878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.size()  # 获取该张量每个维度的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70b475c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.size(0) # 获取张量t第0维的大小"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb408c8",
   "metadata": {},
   "source": [
    "对于张量形状的改变，通常使用以下几种方法\n",
    "- `view()`,\n",
    "- `reshape()`\n",
    "- `narrow()`\n",
    "- `expand()`\n",
    "- `transpose()`\n",
    "\n",
    "| 特性         | view()                                    | reshape()                               |\n",
    "| ------------ | ----------------------------------------- | --------------------------------------- |\n",
    "| 内存连续要求 | 必须是 contiguous                        | 自动处理非 contiguous                  |\n",
    "| 是否更灵活   | 较严格                                   | 更灵活、更健壮                         |\n",
    "| 底层实现     | 直接修改 tensor 的 view                  | 可触发一次数据拷贝                     |\n",
    "| 失败可能性   | 非 contiguous 会报错                      | reshape 会自动处理                     |\n",
    "| 推荐场景     | 性能优先，数据连续场景                   | 大多数场景推荐 reshape (更安全)       |\n",
    "\n",
    "总结就是:\n",
    "- `reshape`通过拷贝并使用原tensor的基础数据(而非共享内存地址)以返回一个具有新shape的新tensor\n",
    "- `view`通过共享内存地址的方式使用原tensor的基础数据，通过改变数据读取方式来返回一个具有新shape的新tensor\n",
    "\n",
    "`reshape`函数不依赖tensor在内存的连续性，当内存连续时，该函数与`torch.view()`函数等价，当内存不连续时，会自动复制后再改变形状，相当于`contiguous().view()`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13161c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6],\n",
       "        [7, 8]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8]]) # 创建形状为(2, 4)的张量\n",
    "y = torch.reshape(x, (4, 2)) # 将张量x重塑为形状为(4, 2)的张量\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a359d9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6],\n",
       "        [7, 8]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8]]) # 创建形状为(2, 4)的张量\n",
    "y = x.view(4, 2) # 将张量x重塑为形状为(4, 2)的张量\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4cedf41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "y = torch.narrow(x, 0, 0, 2)  # 沿第 0 维从索引 0 开始，长度为 2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbc8d231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]],\n",
       "\n",
       "        [[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]],\n",
       "\n",
       "        [[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "y = x.expand(3, 3, 3)  # 将张量x沿新增加的第2维扩展为长度为3\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b6f55dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5142,  1.0629, -0.6766],\n",
       "        [-1.3301, -1.8489, -0.1979]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef99868d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5142, -1.3301],\n",
       "        [ 1.0629, -1.8489],\n",
       "        [-0.6766, -0.1979]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.transpose(x, 1, 0)\n",
    "y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "661b1ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5142, -1.3301],\n",
       "        [ 1.0629, -1.8489],\n",
       "        [-0.6766, -0.1979]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.transpose(x, 0, 1)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c382a9f",
   "metadata": {},
   "source": [
    "在PyTorch中，只有很少几个操作是不改变tensor的内容本身，而只是重新定义下标与元素的对应关系的。换句话说，这种操作不进行数据拷贝和数据的改变，变的是元数据(形状、存储偏移量和步长)。\n",
    "\n",
    "会改变元数据的操作是：\n",
    "\n",
    "- `narrow()`\n",
    "- `view()`\n",
    "- `expand()`\n",
    "- `transpose()`\n",
    "\n",
    "我们以`transpose()`为例，当我们进行转置操作时，并不会创建一个新的张量，而只是修改了原张量的一些属性，使得此时的offset和stride是与转置张量相对应的。转置的张量和原张量的内存是共享的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "036743b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x为 tensor([[-0.3474,  0.9392],\n",
      "        [-1.0937,  1.2490],\n",
      "        [-0.8544, -0.7618]])\n",
      "y为 tensor([[-0.3474, -1.0937, -0.8544],\n",
      "        [ 0.9392,  1.2490, -0.7618]])\n",
      "修改后:\n",
      "x为 tensor([[12.0000,  0.9392],\n",
      "        [-1.0937,  1.2490],\n",
      "        [-0.8544, -0.7618]])\n",
      "y为 tensor([[12.0000, -1.0937, -0.8544],\n",
      "        [ 0.9392,  1.2490, -0.7618]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3,2)\n",
    "y = torch.transpose(x, 0, 1)\n",
    "print(\"x为\", x)\n",
    "print(\"y为\", y)\n",
    "\n",
    "print(\"修改后:\")\n",
    "y[0,0] = 12\n",
    "print(\"x为\", x)\n",
    "print(\"y为\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5349c5b8",
   "metadata": {},
   "source": [
    "可以看到在改变`y`中元素值的同时，`x`的元素的值也发生了变化。\n",
    "\n",
    "`y`还是指向`x`变量处的位置，只是说记录了`transpose`这个变化的布局。如果想要断开两个变量之间的依赖，就要使用`contiguous()`对`x`进行变化，当调用此函数时，会强制拷贝一份张量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4df171ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x为 tensor([[ 1.0106, -1.3623],\n",
      "        [-0.0032, -1.5041],\n",
      "        [-0.5004,  3.0577]])\n",
      "y为 tensor([[ 1.0106, -0.0032, -0.5004],\n",
      "        [-1.3623, -1.5041,  3.0577]])\n",
      "修改后:\n",
      "x为 tensor([[ 1.0106, -1.3623],\n",
      "        [-0.0032, -1.5041],\n",
      "        [-0.5004,  3.0577]])\n",
      "y为 tensor([[ 1.2000e+01, -3.1829e-03, -5.0043e-01],\n",
      "        [-1.3623e+00, -1.5041e+00,  3.0577e+00]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3,2)\n",
    "y = torch.transpose(x, 0, 1).contiguous()\n",
    "print(\"x为\", x)\n",
    "print(\"y为\", y)\n",
    "\n",
    "print(\"修改后:\")\n",
    "y[0,0] = 12\n",
    "print(\"x为\", x)\n",
    "print(\"y为\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64be7c2",
   "metadata": {},
   "source": [
    "可以发现，当对y使用了`contiguous()`时，改变y的值时，x没有任何影响。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

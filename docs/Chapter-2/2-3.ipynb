{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "565eff6c",
   "metadata": {},
   "source": [
    "### 2.3.1 单个张量的函数运算\n",
    "\n",
    "在2.2节中，我们介绍了一些基本的张量的基本操作。在撰写深度学习项目时，我们往往会遇到另一类操作-张量的运算。例如，对于张量做四则运算、线性变换或激活。这些基础操作可以通过PyTorch中的一些函数实现。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c030acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7474, 0.7519, 0.7765, 0.6680, 0.3413],\n",
       "        [0.6366, 0.3437, 0.5580, 0.9147, 0.5428],\n",
       "        [0.4006, 0.2978, 0.9326, 0.8999, 0.9007],\n",
       "        [0.6733, 0.8226, 0.5247, 0.0224, 0.5228]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "t1 = torch.rand(4, 5)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69add818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8645, 0.8671, 0.8812, 0.8173, 0.5842],\n",
       "        [0.7979, 0.5863, 0.7470, 0.9564, 0.7368],\n",
       "        [0.6329, 0.5457, 0.9657, 0.9486, 0.9491],\n",
       "        [0.8206, 0.9070, 0.7244, 0.1495, 0.7231]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(t1) # 张量的平方根"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6e25871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7474, 0.7519, 0.7765, 0.6680, 0.3413],\n",
       "        [0.6366, 0.3437, 0.5580, 0.9147, 0.5428],\n",
       "        [0.4006, 0.2978, 0.9326, 0.8999, 0.9007],\n",
       "        [0.6733, 0.8226, 0.5247, 0.0224, 0.5228]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "247b56c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8645, 0.8671, 0.8812, 0.8173, 0.5842],\n",
       "        [0.7979, 0.5863, 0.7470, 0.9564, 0.7368],\n",
       "        [0.6329, 0.5457, 0.9657, 0.9486, 0.9491],\n",
       "        [0.8206, 0.9070, 0.7244, 0.1495, 0.7231]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.sqrt_()  # 在原张量上进行操作\n",
    "t1  # 张量的值被改变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33bc50a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.2051)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(t1)  # 张量所有元素求和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dc138d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.1159, 2.9061, 3.3183, 2.8718, 2.9931])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(t1, 0) # 对第0维的元素求和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bfce21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.2051)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(t1, [0,1]) # 对第0维和第1维的元素求和  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fd72744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7603)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(t1, [0,1]) # 对第0维和第1维的元素求平均"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb03d68d",
   "metadata": {},
   "source": [
    "对于上述求平方根和求平均值，也可以使用张量自带的方法进行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75ab6662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7603)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.sqrt()\n",
    "t1.mean([0,1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95f2e03",
   "metadata": {},
   "source": [
    "对于大多数我们常用的函数，一般有两种调用方式。一种可以是使用张量的内置方法，另一种则是使用torch自带的函数，这两种的操作结果均相同。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8fab95",
   "metadata": {},
   "source": [
    "### 2.3.2 多个张量的函数运算\n",
    "\n",
    "除了前面对单个张量作为参数进行操作外，还有以两个张量作为参数的操作。比如，两个形状相同的张量之间的逐个元素的四则运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2fcc684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1:\n",
      " tensor([[0.4987, 0.0617, 0.1971],\n",
      "        [0.0913, 0.3373, 0.5552]])\n",
      "t2:\n",
      " tensor([[0.1045, 0.8589, 0.8635],\n",
      "        [0.6098, 0.4399, 0.4111]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.rand(2 ,3)\n",
    "t2 = torch.rand(2 ,3)\n",
    "print(\"t1:\\n\", t1)\n",
    "print(\"t2:\\n\", t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb06287b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6032, 0.9206, 1.0606],\n",
       "        [0.7011, 0.7772, 0.9662]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.add(t2)  # 逐元素相加，不改变参与运算张量的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e644742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6032, 0.9206, 1.0606],\n",
       "        [0.7011, 0.7772, 0.9662]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 + t2  # 逐元素相加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ecac064e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3942, -0.7972, -0.6664],\n",
       "        [-0.5185, -0.1026,  0.1441]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.sub(t2)  # 逐元素相减，不改变参与运算张量的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca603557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3942, -0.7972, -0.6664],\n",
       "        [-0.5185, -0.1026,  0.1441]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1-t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ffc2913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0521, 0.0530, 0.1702],\n",
       "        [0.0557, 0.1484, 0.2282]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.mul(t2)  # 逐元素相乘，不改变参与运算张量的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6f3ab5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0521, 0.0530, 0.1702],\n",
       "        [0.0557, 0.1484, 0.2282]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1*t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5680c787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.7706, 0.0718, 0.2283],\n",
       "        [0.1497, 0.7668, 1.3506]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.div(t2)  # 逐元素相除，不改变参与运算张量的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32fc75da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.7706, 0.0718, 0.2283],\n",
       "        [0.1497, 0.7668, 1.3506]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1/t2 # 逐元素相除"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216f0cd7",
   "metadata": {},
   "source": [
    "同样的，这些内置的方法也有“下划线”版本，可以改变调用方法中张量的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e779b38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6032, 0.9206, 1.0606],\n",
       "        [0.7011, 0.7772, 0.9662]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.add_(t2)  # 逐元素相加，改变调用方法中张量的值\n",
    "t1  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975b0a79",
   "metadata": {},
   "source": [
    "### 2.3.3 张量的极值和排序\n",
    "\n",
    "我们通常在编写代码时，要获得张量(沿着某个维度)的最大值或最小值，以及这些值所在的位置，此时我们便可以使用`max`和`min`。通过传入具体的维度，同时返回该维度最大和最小值的位置，以及对应最大值和最小值组成的元组(Tuple)。\n",
    "\n",
    "同时我们将介绍排序函数`sort`(其默认顺序为从小到大，如果要从大到小则需要设置参数为`descending=True`)，同样传入具体需要排序的维度，将返回排序后的张量，以及对应排序后元素在原始张量上的位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02e90b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9481, -0.0889, -0.2772, -0.5187],\n",
       "        [-0.4270,  0.5304, -0.8407, -0.3956],\n",
       "        [-1.1071,  0.8501,  0.3515, -1.5352]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(3, 4) # 创建一个3行4列的张量\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4286354a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 2, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(t, dim=0)  # 返回沿着第0个维度，极大值所在的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79f5303b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 1, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.argmin(dim=0)  # 返回沿着第0个维度，极小值所在的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59425c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.9481, 0.5304, 0.8501]),\n",
       "indices=tensor([0, 1, 1]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(t, dim=-1)  # 返回沿着最后一个维度，极大值及其位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c700129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.min(\n",
       "values=tensor([-1.1071, -0.0889, -0.8407, -1.5352]),\n",
       "indices=tensor([2, 0, 1, 2]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.min(0)  # 返回沿着第0个维度，极小值及其位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d89db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([[-0.5187, -0.2772, -0.0889,  0.9481],\n",
       "        [-0.8407, -0.4270, -0.3956,  0.5304],\n",
       "        [-1.5352, -1.1071,  0.3515,  0.8501]]),\n",
       "indices=tensor([[3, 2, 1, 0],\n",
       "        [2, 0, 3, 1],\n",
       "        [3, 0, 2, 1]]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sort(-1)  # 沿着最后一个维度排序，返回排序后的张量和张量元素在该维度的原始位置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12e55c8",
   "metadata": {},
   "source": [
    "### 2.3.4 矩阵的乘法\n",
    "\n",
    "除了四则运算，最大和最小值运算，以及排序外。两个张量作为参数进行矩阵乘法(线性变换)也非常重要。有以下几种方法可以实现矩阵乘法运算。\n",
    "- torch中的函数\n",
    "- 张量内置的方法\n",
    "- python中固定的运算符号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f812925e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " tensor([[ 0.7416,  0.5422,  0.1718,  0.9976],\n",
      "        [-0.5226, -1.1478,  0.2866,  0.4774],\n",
      "        [ 0.4626,  0.0871, -0.1435, -0.7787]])\n",
      "b:\n",
      " tensor([[ 1.3191, -0.2684,  0.3255],\n",
      "        [ 0.2111, -1.3144,  0.6840],\n",
      "        [-0.2207, -1.8773, -0.0635],\n",
      "        [ 0.4617,  0.0399, -0.8543]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3, 4)\n",
    "b = torch.randn(4,3)\n",
    "print(\"a:\\n\", a)\n",
    "print(\"b:\\n\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a35f9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5153e+00, -1.1945e+00, -2.5085e-01],\n",
       "        [-7.7448e-01,  1.1299e+00, -1.3812e+00],\n",
       "        [ 3.0072e-01, -4.1564e-04,  8.8450e-01]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(a, b)  # 矩阵乘法，返回一个新的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4d60448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5153e+00, -1.1945e+00, -2.5085e-01],\n",
       "        [-7.7448e-01,  1.1299e+00, -1.3812e+00],\n",
       "        [ 3.0072e-01, -4.1564e-04,  8.8450e-01]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.mm(b)  # 矩阵乘法，返回一个新的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eba9a29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5153e+00, -1.1945e+00, -2.5085e-01],\n",
       "        [-7.7448e-01,  1.1299e+00, -1.3812e+00],\n",
       "        [ 3.0072e-01, -4.1564e-04,  8.8450e-01]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a@b  # 矩阵乘法，返回一个新的张量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e21ce6",
   "metadata": {},
   "source": [
    "在深度学习项目中，经常用到的三维张量的数据，一般来说，第一个维度是批次大小。因此，可以将三维张量看作是一个批次数量的矩阵叠加在一起。在这种情况下，如果两个张量做矩阵乘法，一般情况是沿着批次方向分别对每个矩阵做成发，最后将所有乘积的结果整合在一起。如果是大小$b\\times m \\times k$和$b\\times k \\times n$的张量相乘，那么结果应该是一个$b\\times m \\times n$的张量。也就是说两个张量的第一维是相等的，然后第一个张量的第三维和第二个张量的第二维度要求一样，对于剩下的则不做要求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc5f7834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " tensor([[[-0.5726,  0.3904, -1.3048,  1.2376],\n",
      "         [-0.0350, -0.9203, -1.2111,  1.3856],\n",
      "         [ 1.1742,  1.4521,  0.1331, -1.0468]],\n",
      "\n",
      "        [[ 0.4609,  0.5092,  0.9264,  0.2154],\n",
      "         [-1.0332,  0.2447, -2.3390,  0.2792],\n",
      "         [-0.1505, -1.0384, -1.9209,  0.7610]]])\n",
      "b:\n",
      " tensor([[[ 0.6359,  0.2232, -0.6263],\n",
      "         [-0.7679, -0.5404, -1.4962],\n",
      "         [-2.0298, -2.0135,  1.8570],\n",
      "         [-0.4898, -0.2488, -0.9898]],\n",
      "\n",
      "        [[-0.0143,  0.5537,  0.8624],\n",
      "         [-0.5143,  0.0657, -2.4071],\n",
      "         [-0.7975, -0.5584, -1.1611],\n",
      "         [ 2.1338, -0.7168, -1.2403]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 3, 4)\n",
    "b = torch.randn(2, 4, 3)\n",
    "print(\"a:\\n\", a)\n",
    "print(\"b:\\n\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "56041faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3786,  1.9806, -3.8736],\n",
       "         [ 2.4642,  2.5834, -2.2216],\n",
       "         [-0.1258, -0.5301, -1.6248]],\n",
       "\n",
       "        [[-0.5476, -0.3831, -2.1709],\n",
       "         [ 2.3501,  0.5501,  0.8895],\n",
       "         [ 3.6919,  0.3757,  3.6561]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(a, b)  # 批量矩阵乘法，返回一个新的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "453379ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3786,  1.9806, -3.8736],\n",
       "         [ 2.4642,  2.5834, -2.2216],\n",
       "         [-0.1258, -0.5301, -1.6248]],\n",
       "\n",
       "        [[-0.5476, -0.3831, -2.1709],\n",
       "         [ 2.3501,  0.5501,  0.8895],\n",
       "         [ 3.6919,  0.3757,  3.6561]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.bmm(b)  # 批量矩阵乘法，返回一个新的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ed526cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3786,  1.9806, -3.8736],\n",
       "         [ 2.4642,  2.5834, -2.2216],\n",
       "         [-0.1258, -0.5301, -1.6248]],\n",
       "\n",
       "        [[-0.5476, -0.3831, -2.1709],\n",
       "         [ 2.3501,  0.5501,  0.8895],\n",
       "         [ 3.6919,  0.3757,  3.6561]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a@b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d218ff",
   "metadata": {},
   "source": [
    "对于更大维度的张量的乘积，往往要决定张量元素乘积的结果需要沿着哪些维度进行求和，这个过程称为缩并(Contraction)，这时候需要引入爱因斯坦求和约定(einsum)。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
